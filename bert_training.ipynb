{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_masks', 'labels'],\n",
      "    num_rows: 4402\n",
      "})\n",
      "{'ids': '[101, 8827, 15459, 13102, 18491, 3593, 1024, 25801, 2692, 28154, 18888, 1013, 4531, 1024, 1996, 3424, 1011, 7540, 2723, 2013, 7861, 2121, 2290, 1012, 9602, 2597, 2000, 6164, 2341, 2025, 3024, 1012, 6412, 19184, 1024, 1996, 3395, 6019, 2930, 2003, 2761, 3024, 2007, 3424, 1011, 8301, 2094, 6773, 1012, 1999, 1996, 3522, 8774, 1010, 2004, 2112, 1997, 9410, 25536, 6032, 1010, 1996, 9602, 6718, 2282, 5877, 2001, 4993, 1998, 13967, 9100, 1012, 2023, 2435, 1996, 2878, 5877, 1037, 2978, 1997, 1037, 19504, 2298, 1012, 2174, 1010, 1996, 19467, 1010, 4993, 2007, 3424, 1011, 8301, 2094, 6773, 2761, 1010, 2001, 2145, 2200, 2172, 6464, 4346, 3424, 1011, 8301, 2094, 5144, 1012, 3040, 11548, 2023, 2000, 1996, 8827, 3597, 1010, 2174, 2002, 2106, 2025, 5993, 1012, 3040, 2515, 2025, 102]', 'mask': '[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]', 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"processed_severity_data.csv\")[\"train\"]\n",
    "print(dataset)\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.2)  # 80% train, 20% test\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"attention_masks\", \"mask\")\n",
    "test_dataset = test_dataset.rename_column(\"attention_masks\", \"mask\")\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"input_ids\", \"ids\")\n",
    "test_dataset = test_dataset.rename_column(\"input_ids\", \"ids\")\n",
    "\n",
    "# train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "# test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, dataframe, tokenizer, max_len):\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.data = dataframe\n",
    "#         self.comment_text = dataframe.comment_text\n",
    "#         self.targets = self.data.list\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.comment_text)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         comment_text = str(self.comment_text[index])\n",
    "#         comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "#         inputs = self.tokenizer.encode_plus(\n",
    "#             comment_text,\n",
    "#             None,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_len,\n",
    "#             pad_to_max_length=True,\n",
    "#             return_token_type_ids=True\n",
    "#         )\n",
    "#         ids = inputs['input_ids']\n",
    "#         mask = inputs['attention_mask']\n",
    "#         labels = inputs[\"labels\"]\n",
    "\n",
    "\n",
    "#         return {\n",
    "#             'ids': torch.tensor(ids, dtype=torch.long),\n",
    "#             'mask': torch.tensor(mask, dtype=torch.long),\n",
    "#             'labels': torch.tensor(labels, dtype=torch.long),\n",
    "#             'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(train_dataset, **train_params)\n",
    "testing_loader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _, data in enumerate(training_loader, 0):\n",
    "        print(data['ids'])\n",
    "        ids = torch.tensor(data['ids']).to(device, dtype=torch.long)\n",
    "        mask = torch.tensor(data['mask']).to(device, dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(data['label']).to(device, dtype=torch.long)\n",
    "        targets = torch.tensor(data['targets']).to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[101, 8827, 15459, 13102, 18491, 3593, 1024, 21417, 21619, 2509, 18888, 1013, 4531, 1024, 4812, 2044, 4926, 6412, 19184, 1024, 2006, 2251, 2382, 1010, 16798, 2509, 1010, 11113, 6819, 14220, 7303, 2000, 2022, 2207, 2013, 2010, 2851, 3422, 2012, 1019, 1024, 4002, 2572, 2044, 7678, 3155, 2028, 3178, 1997, 1996, 2958, 3422, 1012, 2004, 2009, 2001, 2525, 11695, 1010, 1996, 4611, 2961, 3039, 2032, 2000, 2175, 2091, 1012, 1996, 6258, 2001, 2012, 2712, 1999, 2330, 5380, 1010, 4372, 22494, 2618, 2000, 2710, 1012, 2012, 2105, 5709, 11387, 8093, 2015, 2045, 2001, 2019, 11240, 5043, 5994, 1996, 11113, 6819, 14220, 1012, 11240, 2597, 1024, 4229, 3207, 2290, 2484, 1012, 1021, 1005, 1050, 1013, 11502, 2139, 2290, 2676, 1012, 1015, 1005, 1041, 3058, 1004, 2051, 1024, 13293, 21650, 16798, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 14112, 27814, 2620, 18888, 1013, 4531, 1024, 3417, 1011, 2217, 11240, 2166, 8569, 6977, 2003, 2025, 3201, 2000, 2022, 6908, 2012, 2712, 1006, 1996, 2713, 9231, 2003, 4600, 18399, 2098, 1998, 8534, 1007, 1012, 6412, 19184, 1024, 2044, 1996, 8089, 1010, 1996, 4650, 1997, 11240, 2001, 7039, 1998, 2009, 2001, 5159, 2008, 2019, 3176, 2713, 9231, 2001, 4987, 2000, 1996, 3941, 1998, 2009, 2001, 18399, 2098, 2349, 2000, 3430, 3252, 1012, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 2019, 3176, 9231, 2001, 4987, 2000, 11240, 2000, 4468, 17128, 7085, 2076, 3082, 4633, 3785, 1012, 6149, 3512, 2895, 1024, 3202, 2044, 1996, 10569, 1010, 1996, 3176, 2713, 9231, 2001, 3718, 1998, 1996, 6258, 4484, 1996, 19822, 1997, 11240, 2005, 5057, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 21809, 16703, 2509, 18888, 1013, 4531, 1024, 2195, 3194, 2282, 28315, 2075, 2179, 2007, 1005, 5741, 7192, 24325, 1011, 1045, 1012, 1041, 1012, 4840, 2300, 2240, 2013, 18479, 8458, 5686, 1010, 28030, 2300, 2291, 2712, 5880, 6970, 8663, 2638, 7542, 2240, 1012, 6412, 19184, 1024, 4242, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 1996, 4812, 3936, 2008, 1996, 2708, 3992, 2038, 2042, 4453, 1996, 4650, 1997, 1996, 4840, 2300, 2240, 2013, 18479, 8458, 5686, 1010, 28030, 2300, 2291, 2712, 5880, 6970, 8663, 2638, 7542, 2240, 1010, 2988, 2000, 1996, 2132, 2436, 3625, 2533, 1998, 2035, 4475, 5359, 2006, 2604, 2005, 28667, 3775, 10803, 1012, 1996, 7117, 3426, 1997, 2023, 18888, 3658, 2000, 1996, 1006, 3740, 6032, 1013, 19940, 3277, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 27445, 2683, 2683, 2549, 18888, 1013, 4531, 1024, 1996, 2053, 2595, 16381, 2501, 1997, 1043, 1013, 9686, 1012, 1011, 1011, 1011, 1011, 1011, 2025, 2501, 7919, 2069, 2055, 8909, 2193, 1997, 3194, 3033, 6412, 19184, 1024, 4242, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 2043, 3344, 2041, 1996, 6032, 1997, 29347, 1011, 1042, 2080, 1012, 13341, 10764, 1012, 2708, 3992, 2680, 1996, 5361, 8909, 2193, 1006, 2069, 1040, 22022, 1007, 1999, 2949, 1010, 2323, 2680, 2440, 8909, 1011, 1040, 22022, 4487, 2072, 1011, 14989, 2618, 22407, 10790, 1012, 3626, 3768, 1997, 3716, 1012, 6149, 3512, 2895, 1024, 2708, 3992, 3561, 1996, 2878, 5361, 8909, 2004, 2566, 1996, 2053, 2595, 3205, 1999, 2392, 1997, 8827, 3597, 1012, 2156, 4987, 7760, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 20708, 22203, 2487, 18888, 1013, 4531, 1024, 1996, 3626, 1998, 2051, 2005, 10837, 2686, 4443, 1998, 5343, 12913, 2025, 1999, 23758, 3012, 2007, 4507, 2006, 5840, 1012, 2260, 1012, 16798, 2509, 6412, 19184, 1024, 4242, 6234, 5320, 1024, 3202, 13371, 10837, 2686, 12913, 3189, 1010, 13371, 1996, 7561, 1999, 10984, 1998, 1996, 2561, 2711, 8019, 1999, 1996, 12913, 1012, 7117, 3426, 4106, 1024, 3167, 5876, 1028, 1028, 14710, 8822, 14710, 2501, 18321, 1004, 8822, 1997, 12913, 2636, 6149, 3512, 2895, 1024, 2731, 3024, 2000, 7972, 5073, 2875, 4621, 2501, 18321, 1012, 4652, 3512, 2895, 1024, 4170, 22517, 6631, 1997, 18888, 2000, 4652, 2128, 1011, 14404, 1012, 18888, 3642, 1024, 5840, 14526, 2620, 20010, 27971, 3468, 18888, 1024, 2053, 102, 0, 0]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 17616, 27531, 2475, 18888, 1013, 4531, 1024, 2045, 2003, 2053, 3350, 2008, 1996, 2911, 4842, 2038, 4161, 1996, 4304, 1997, 1996, 6636, 8209, 2006, 2604, 1012, 6412, 19184, 1024, 4242, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 3768, 1997, 6413, 8606, 2006, 14017, 3022, 14371, 1013, 19723, 1012, 2184, 2000, 2022, 3264, 2008, 10578, 3454, 3499, 6851, 3997, 1998, 9211, 16268, 2478, 2593, 1996, 4304, 2030, 1996, 2358, 21293, 3351, 5387, 1997, 1996, 6636, 1012, 6149, 3512, 2895, 1024, 2911, 7347, 2020, 25478, 5411, 2000, 3073, 13266, 6636, 5491, 2164, 2592, 2006, 6636, 4304, 1012, 4652, 3512, 2895, 1024, 3176, 8606, 2001, 3024, 2000, 2035, 6470, 1998, 1996, 3136, 29466, 2000, 5676, 2925, 12646, 2007, 7882, 14017, 3022, 7816, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 25846, 28154, 2509, 18888, 1013, 4531, 1024, 2300, 13749, 8303, 3228, 7142, 8598, 6412, 19184, 1024, 4242, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 1996, 2300, 13749, 8303, 8598, 2291, 2005, 1042, 13876, 2001, 8878, 2349, 2000, 2045, 2001, 1038, 2860, 1999, 1996, 1042, 13876, 1012, 2045, 2001, 2498, 3308, 2007, 1996, 2300, 13749, 8303, 8598, 2291, 2021, 24216, 2011, 1996, 8827, 13186, 1012, 6854, 1010, 2027, 2145, 2404, 2009, 2004, 1037, 18888, 1999, 1996, 10569, 3189, 1012, 6149, 3512, 2895, 1024, 1996, 2911, 1005, 1055, 3095, 2018, 4541, 1013, 6427, 2168, 2000, 1996, 8827, 13186, 1998, 2288, 3970, 2077, 2037, 4487, 3366, 11201, 22379, 3508, 1012, 4652, 3512, 2895, 1024, 3904, 18888, 3642, 1024, 19883, 2475, 20010, 27971, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 26738, 24594, 2629, 18888, 1013, 4531, 1024, 2597, 15887, 6075, 1998, 4118, 2025, 3344, 2041, 2004, 2566, 4844, 6019, 2933, 1012, 6412, 19184, 1024, 2597, 15887, 6075, 4118, 2025, 3344, 2041, 2004, 2566, 4844, 6019, 2933, 6234, 5320, 1024, 3040, 8182, 1996, 12653, 2007, 9163, 3738, 1998, 5372, 18856, 8486, 10803, 2015, 3024, 7117, 3426, 4106, 1024, 2582, 2000, 2256, 4812, 2029, 2001, 2864, 1010, 2009, 2001, 4453, 2008, 1996, 6185, 4859, 2961, 2001, 2150, 13233, 1998, 2071, 2025, 7919, 10580, 2030, 4863, 12949, 2054, 2001, 1996, 4118, 2109, 7978, 1013, 14801, 1999, 1996, 6019, 2933, 1012, 25416, 21898, 3672, 2731, 2001, 3024, 2011, 1996, 3040, 2006, 5372, 10467, 1998, 9073, 1997, 1996, 2592, 2004, 3223, 1012, 1037, 26236, 4160, 102]']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[129], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m     ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      6\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      7\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'input_ids'"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            print(data[\"input_ids\"])\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[101, 8827, 15459, 13102, 18491, 3593, 1024, 12169, 2581, 23833, 18888, 1013, 4531, 1024, 2557, 6046, 5997, 7127, 1024, 6046, 8080, 1999, 2224, 1012, 3626, 2020, 2025, 5204, 2055, 2009, 1012, 6412, 19184, 1024, 2025, 2825, 2000, 2224, 13938, 5104, 2015, 3941, 1999, 2553, 1997, 5057, 2349, 2000, 2659, 3977, 1997, 5057, 10274, 1012, 6234, 5320, 1024, 11339, 3738, 6439, 12407, 2006, 6046, 5997, 1012, 3738, 2025, 7919, 5220, 3550, 2007, 13938, 5104, 2015, 3941, 1998, 4216, 1997, 2373, 4425, 7117, 3426, 4106, 1024, 11339, 3738, 6439, 12407, 2006, 6046, 5997, 1012, 3738, 2025, 7919, 5220, 3550, 2007, 13938, 5104, 2015, 3941, 1998, 4216, 1997, 2373, 4425, 6149, 3512, 2895, 1024, 3625, 2005, 13938, 5104, 2015, 3941, 2961, 2001, 10290, 2000, 9975, 3582, 9095, 1997, 3679, 1010, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 12651, 8889, 2581, 18888, 1013, 4531, 1024, 3082, 3033, 8250, 2006, 5877, 2648, 11366, 2200, 3532, 1013, 5410, 25210, 2075, 2109, 1012, 2025, 5123, 2013, 2929, 1012, 6412, 19184, 1024, 3082, 3033, 8250, 2006, 5877, 2648, 11366, 2200, 3532, 1013, 5410, 25210, 2075, 2109, 1012, 2025, 5123, 2013, 2929, 1012, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 1996, 2214, 2109, 8622, 2001, 4015, 2000, 1996, 2364, 5877, 2005, 13148, 2007, 1996, 13044, 1999, 2023, 3417, 1012, 2174, 1010, 2027, 2020, 2025, 3970, 2011, 1996, 7684, 4322, 2012, 1996, 3417, 1012, 6149, 3512, 2895, 1024, 1996, 2214, 2109, 8622, 2001, 4015, 2503, 1996, 3573, 1998, 7119, 2007, 7318, 25210, 8613, 1012, 4652, 3512, 2895, 1024, 1996, 8089, 2001, 6936, 2007, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 17616, 2692, 24594, 18888, 1013, 4531, 1024, 3194, 2282, 9625, 13038, 2179, 2000, 5383, 9987, 6900, 1013, 17111, 2102, 1999, 3365, 5269, 1012, 6412, 19184, 1024, 3194, 2282, 9625, 13038, 2179, 2000, 5383, 9987, 6900, 1013, 17111, 2102, 1999, 3365, 5269, 1012, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 1996, 2911, 1005, 1055, 10604, 2323, 3202, 6366, 1996, 6900, 1013, 17111, 2102, 2044, 6032, 1998, 7192, 1997, 1996, 10394, 1010, 2021, 2027, 2020, 5697, 2007, 2060, 6032, 2147, 1998, 2245, 2027, 2071, 2074, 4550, 2039, 1996, 6900, 1013, 17111, 2102, 1999, 1996, 9625, 13038, 2101, 1012, 3937, 1013, 10318, 3426, 1024, 14710, 10429, 1010, 27988, 1997, 7882, 5073, 1012, 6149, 3512, 2895, 1024, 6530, 2752, 1997, 1996, 9625, 4974, 102]', '[101, 8827, 15459, 13102, 18491, 3593, 1024, 27253, 21084, 2475, 18888, 1013, 4531, 1024, 28030, 2300, 2968, 2933, 2001, 2025, 7172, 1006, 28030, 2300, 3949, 2291, 2001, 5361, 2197, 2095, 1007, 1012, 6412, 19184, 1024, 4242, 6234, 5320, 1024, 4242, 7117, 3426, 4106, 1024, 2194, 2005, 2070, 3114, 4771, 2000, 3073, 1996, 2047, 1038, 2860, 8737, 2000, 6258, 2044, 1996, 8272, 1997, 2047, 1038, 26677, 2015, 1012, 2009, 2001, 3530, 2008, 1996, 2047, 1038, 2860, 8737, 2097, 2022, 2741, 2000, 6258, 2320, 1038, 26677, 2015, 2003, 5361, 1999, 1996, 4318, 14647, 1012, 2006, 1996, 2060, 2192, 1010, 6258, 2001, 4012, 24759, 10732, 3372, 2007, 2054, 2038, 2042, 3530, 1998, 3478, 2000, 3582, 2039, 1996, 2047, 1038, 2860, 8737, 1012, 6149, 3512, 2895, 1024, 6258, 3202, 11925, 1996, 102]']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m----> 2\u001b[0m     outputs, targets \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(outputs) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m      4\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(targets, outputs)\n",
      "Cell \u001b[1;32mIn[62], line 8\u001b[0m, in \u001b[0;36mvalidation\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(testing_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      9\u001b[0m     mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     10\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ids'"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maritime_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
